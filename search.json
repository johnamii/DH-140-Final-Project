[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/Final Project.html",
    "href": "posts/Final Project.html",
    "title": "Final Project",
    "section": "",
    "text": "In spring of this year, the pop culture scene erupted as drama unfolded between two of the biggest hip-hop artists of all time, Kendrick Lamar and Drake. During this time, there were countless posts, reactions, and most importantly a groundbreaking series of diss tracks back and forth between the two artists. Now that the dust has settled, the popular consensus is that Kendrick “won” this feud, boosting his reputation and costing Drake a huge blow to his. The stories, allegations, and contexts of this conflict have been endlessly covered online, so I thought it would be a great opportunity to brush over that and approach it from a different angle. That leads me to my research question:\nCan we use data to understand some factors that led to Kendrick ‘winning’ his beef with Drake?\nI intend to answer this question with an exploratory project, hoping to glean interesting insights on the drama using data. We’ll explore the conflict through popular trends, linguistic analysis, and music data.\n\n\n\nWhen exploring data and thinking of ideas for this project, I changed tracks multiple times, exploring pathways with datasets for world cities, veganism, and jazz music. Eventually I circled around to wanting to work with music data and the spotify API, and settled on this topic due to its relevence, recency, and countless angles to approach it from. While I’m not the biggest pop culture or hip-hop fan, I’m very familiar with both artists, their reputations, and what happened in this series of events. I think it provides the perfect opportunity to explore using my interests of music and linguistics.\n\n\n\nAs mentioned, I’m definitely no expert in hip-hop or pop culture, and only hope to glean interesting information on the events that unfolded. I won’t cover any allegations (some of which were very serious) or speculation, but only music and music trends. Finally, I should say I’m personally a huge Kendrick fan and not the biggest fan of Drake’s and this has been the case for quite some time. But I don’t think my bias should affect the outcome of this research beyond my saying that Kendrick ‘won’, which apperas to be the consensus.\nAlso note that many see the kickstart to the conflict between Kendrick and Drake was a song in which Kendrick featured titled “Like that” by Metro Boomin. For simplicity’s sake, we’ll exclude that piece and focus only on the music dropped by our two artists.\nFinally, during the beef there were a couple of smaller diss tracks which, for some reason, are not avaiable on Spotify. Namely, Taylor Made Freestyle and 6:16 in LA. Since they’re not available, they won’t be included in the data.\n\n\n\n\nMy analysis will be heavily focused on the data that is available via the Spotify Web API, and hopefully will be limited to not surpass their free usage limits. To supplement the Spotify data, I’ll be using the Genius API to get lyrics for the tracks I analyze. Using this data, I hope to analyze listening trends, linguistic qualities of lyrics, and important relationships of whatever can be extrapolated.\nTo access the Spotify API data, I’ll be using the popular Python wrapper for it called Spotipy for ease of access. Through this, I’ll have access to various endpoints for data on albums, tracks, artists, and musical elements. I’ll source entirely from music by the two artists using this, and build on that by getting the lyrics data from Genius.\nI’ll be getting the data with the requests library. To handle it, I’ll use pandas. To visualize the data I’ll use matplotlib, and for linguistic analysis I’ll use BeautifulSoup and nltk.\n\n\n\nPopularity score refers to the popularity of a single track, ranked by Spotify out of 100, based on amount of plays and recency\n\n\n\n\nTo get started, we need to initialize the project by importing required libraries and packages, then setting up variables to use them.\n\n\nHere, I’ll leave all the major function declarations that will interact with the APIs to get data. There are three sections: * API functions, to interact with the APIs and get data for us to use * Helper functions, to serve as glue between other functions and to help clean our data * Analysis functions, to do stuff with the data and extrapolate information from it\n\n# Genius API functions\n############################################\n\ndef get_track_lyrics(track_name, artist_name):\n    song = genius.search_song(track_name, artist_name)\n    if song:\n        return song.lyrics\n    else:\n        print(f\"Lyrics not found for {track_name} by {artist_name}.\")\n\n# Spotipy API functions\n#############################################\n\ndef get_artist_albums(name):\n    results = sp.search(q=f'artist:{name}', type='artist')\n    artist = results['artists']['items'][0]\n    artist_id = artist['id']\n\n    albums = sp.artist_albums(artist_id, album_type='album')['items']\n    singles = sp.artist_albums(artist_id, album_type='single')['items']\n\n    all_albums = []\n    for album in albums + singles:\n        album_info = {\n            'name': album['name'],\n            'id': album['id'],\n            'artist_name': name,\n            'release_date': album['release_date'],\n            'total_tracks': album['total_tracks'],\n            'album_type': album['album_type']\n        }\n        all_albums.append(album_info)\n\n    return all_albums\n\ndef get_album_tracks(album_id, include_lyrics):\n    tracks = sp.album_tracks(album_id)['items']\n    track_list = []\n    for track in tracks:\n        track_item = sp.track(track[\"id\"])\n        if include_lyrics:\n            track_lyrics = get_track_lyrics(track['name'], track['artists'][0][\"name\"])\n        \n        track_info = {\n            'name': track['name'],\n            'artist_name': track['artists'][0]['name'],\n            'track_number': track['track_number'],\n            'duration_ms': track['duration_ms'],\n            'popularity': track_item['popularity'],\n            'lyrics': track_lyrics if include_lyrics else None\n        }\n        track_list.append(track_info)\n    return track_list\n\n\n## Analysis Functions\n\n# Get the average sentiment score of the words in a song\ndef clean_and_tokenize_lyrics(lyrics):\n    start_index = lyrics.find('Lyrics')\n    if start_index != -1:\n        lyrics = lyrics[start_index + len(\"Lyrics\"):]\n        \n    cleaned_lyrics = re.sub(r'[^\\w\\s]', '', lyrics)\n    cleaned_lyrics = re.sub(r'\\s+', ' ', cleaned_lyrics).strip()\n\n    lyric_words = nltk.word_tokenize(cleaned_lyrics)\n    return lyric_words\n\ndef get_words_avg_sentiment(lyrics, exclude_neutral):\n    words = clean_and_tokenize_lyrics(lyrics)\n    compound_sum = 0\n    word_count = len(words)\n    for word in words:\n        score = sentiment_analyzer.polarity_scores(word)['compound']\n        # optionally exclude neutrals for a more powerful score\n        if exclude_neutral and score == 0:\n            # reduce average divisor to effectively remove 0 scores\n            word_count -= 1\n        compound_sum += score\n    return compound_sum / word_count\n\ndef get_track_sentiment_development(lyrics, duration_ms, exclude_neutral):\n    # assuming an average of 100bpm, we get ~2.4 seconds per bar. Our period will be ~8 bars\n    words = clean_and_tokenize_lyrics(lyrics)\n    total_bars = duration_ms / 1000 / 2.4\n    words_per_bar = len(words) / total_bars\n    words_per_4_bars = round(words_per_bar * 4)\n\n    grouped_sentiment_scores = []\n    index = 0\n    counter = 0\n    cur_score = 0\n    while index &lt; len(words):\n        if counter == words_per_4_bars:\n            grouped_sentiment_scores.append(cur_score)\n            counter = 0\n            cur_score = 0\n        cur_score += sentiment_analyzer.polarity_scores(words[index])[\"compound\"]\n        index += 1\n        counter += 1\n    return grouped_sentiment_scores\n\n\n\n\n\n\nNow that we have a strategy and infrastructure in place to get the data, we can get it into our environment and start organizing it for analysis.\n\n\nThis cell will contain a lot of API calls while defining the most important variables. Have caution calling it more than once, as rate limits might start applying.\n\n# Get all albums from both artists respectively\n    # API call get_artists_albums\nkendrick_albums = get_artist_albums(\"Kendrick Lamar\")\ndrake_albums = get_artist_albums(\"Drake\")\n\n\n# Inject popularity score to each album via API call\nfor album in kendrick_albums:\n    tracks = get_album_tracks(album['id'], False)\n    album['avg_popularity'] = calc_album_popularity(tracks)\nfor album in drake_albums:\n    tracks = get_album_tracks(album['id'], False)\n    album['avg_popularity'] = calc_album_popularity(tracks)\n\n\n# Clean corrupted item\ndrake_albums = [album for album in drake_albums if len(album['release_date']) == 10]\nkendrick_albums = [album for album in kendrick_albums if len(album['release_date']) == 10]\n\n# Optionally combine all their albums and sort them by release date\nkendrick_and_drake_albums = kendrick_albums + drake_albums\nkendrick_and_drake_albums.sort(key=lambda x: x['release_date'])\n\n# Define the start point of the beef\nsplit_index = find_item_index(kendrick_and_drake_albums, \"Push Ups\")\n\n# Create split of albums from before and during the beef\nbeef_singles = kendrick_and_drake_albums[split_index:]\npre_beef_albums = kendrick_and_drake_albums[:split_index]\n\n# Exclude post-beef track from list\nbeef_singles = [album for album in beef_singles if album[\"name\"] != \"Sideways\"]\n\n# Swap Meet the Grahams (later) and Family Matters (earlier), which were released on the same day\nmtg_index = find_item_index(beef_singles, \"Meet the Grahams\")\nfm_index = find_item_index(beef_singles, \"Family Matters\")\nif mtg_index != -1 and fm_index != -1:\n    beef_singles[fm_index], beef_singles[mtg_index] = beef_singles[mtg_index], beef_singles[fm_index]\n\n\nbeef_tracks = []\nfor single in beef_singles:\n    track = get_album_tracks(single[\"id\"], True)\n    beef_tracks.append(track[0])\n\n\n\n\n\n# Drake all albums and release years, showing popularity\ndrake_release_dates = [datetime.strptime(album['release_date'], '%Y-%m-%d') for album in drake_albums]\ndrake_popularities = [album[\"avg_popularity\"] for album in drake_albums]\ndrake_album_colors = ['green' if album['album_type'].lower() == 'album' else 'goldenrod' for album in drake_albums]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(drake_release_dates, drake_popularities, color=drake_album_colors,width=30)\n\nplt.title('Popularity scores of all Drake releases', fontsize=16)\nplt.xlabel('Album Release Date', fontsize=12)\nplt.ylabel('Popularity score', fontsize=12)\n\nplt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n\nlegend_elements = [Patch(facecolor='goldenrod', edgecolor='goldenrod', label='Single'),\n                   Patch(facecolor='green', edgecolor='green', label='Album')]\nplt.legend(handles=legend_elements)\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Kendrick all albums and release years, showing popularity\nkendrick_release_dates = [datetime.strptime(album['release_date'], '%Y-%m-%d') for album in kendrick_albums]\nkendrick_popularities = [album[\"avg_popularity\"] for album in kendrick_albums]\nkendrick_album_colors = ['green' if album['album_type'].lower() == 'album' else 'goldenrod' for album in kendrick_albums]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(kendrick_release_dates, kendrick_popularities, color=kendrick_album_colors,width=30)\n\nplt.title('Popularity scores of all Kendrick releases', fontsize=16)\nplt.xlabel('Album Release Date', fontsize=12)\nplt.ylabel('Popularity score', fontsize=12)\n\nplt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n\nlegend_elements = [Patch(facecolor='goldenrod', edgecolor='goldenrod', label='Single'),\n                   Patch(facecolor='green', edgecolor='green', label='Album')]\nplt.legend(handles=legend_elements)\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(12, 6))\n\nplt.plot(drake_release_dates, drake_popularities, 'o', label='Drake', color=\"crimson\")\n\nplt.plot(kendrick_release_dates, kendrick_popularities, 'o', label='Kendrick Lamar', color=\"skyblue\")\n\nplt.title(\"Both Artists' Releases Popularities Over Time\", fontsize=16)\nplt.xlabel(\"Release Date\", fontsize=12)\nplt.ylabel(\"Popularity Score\", fontsize=12)\nplt.legend()\n\nplt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n\nplt.grid(True, linestyle='--', alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nbeef_titles = [f\"{album['name']} \\n {album['artist_name']}\" for album in beef_singles]\nbeef_release_dates = [datetime.strptime(album['release_date'], '%Y-%m-%d') for album in beef_singles]\nbeef_colors = [\"crimson\" if \"Drake\" in track[\"artist_name\"] else \"skyblue\" for track in beef_tracks]\nbeef_popularities = [track['popularity'] for track in beef_tracks]\n\nfig, ax = plt.subplots(figsize=(12, 6))\ny_levels = [1.5, 1.5, 1.5, 2, 1.5]\n\nfor i, (date, title, color) in enumerate(zip(beef_release_dates, beef_titles, beef_colors)):\n    y = y_levels[i % len(y_levels)]\n    ax.scatter(date, y, s=75, color=color)\n    ax.annotate(title, (date, y), xytext=(10, 0), \n                textcoords='offset points', ha='center', va='top',\n                rotation=45)\n\nax.set_ylim(1, 2.5)\nax.set_yticks([])  \n\nplt.title('Beef Release Timeline', fontsize=16)\nplt.xlabel('Release Date', fontsize=12)\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Popularity of each beef track\nbeef_popularities = [track['popularity'] for track in beef_tracks]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(beef_titles, beef_popularities, color=beef_colors)\n\nplt.title('Popularity of each track during the beef', fontsize=16)\nplt.xlabel('Track Title', fontsize=12)\nplt.ylabel('Popularity score', fontsize=12)\n\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height,\n             f'{height}',\n             ha='center', va='bottom')\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n# Average sentiment track by track of beef\nbeef_avg_sentiments = [get_words_avg_sentiment(track['lyrics'], False) for track in beef_tracks]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(beef_titles, beef_avg_sentiments, color=beef_colors)\n\nplt.title('Average sentiment score of beef track lyrics, including neutral words', fontsize=16)\nplt.xlabel('Track Title', fontsize=12)\nplt.ylabel('Words average sentiment score', fontsize=12)\n\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height,\n             f'{height}',\n             ha='center', va='bottom')\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Average sentiment track by track of beef\nbeef_avg_sentiments = [get_words_avg_sentiment(track['lyrics'], True) for track in beef_tracks]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(beef_titles, beef_avg_sentiments, color=beef_colors)\n\nplt.title('Average sentiment score of beef track lyrics, excluding neutral words', fontsize=16)\nplt.xlabel('Track Title', fontsize=12)\nplt.ylabel('Words average sentiment score', fontsize=12)\n\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height,\n             f'{height}',\n             ha='center', va='bottom')\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Sentiment development during each track\n\nfor track in beef_tracks:\n    sentiment_development_scores = get_track_sentiment_development(track['lyrics'], track[\"duration_ms\"], False)\n    fig, ax = plt.subplots()\n    bars = ax.bar(range(len(sentiment_development_scores)), sentiment_development_scores)\n    \n    ax.set_xlabel(f\"Index per 4 bars of track\")\n    ax.set_ylabel('Summed sentiment score')\n    ax.set_title(f\"Sentiment development of {track['name']} by {track['artist_name']}\")\n    \n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that this functionality occasionally won’t work due to inconsistency with the API. If it times out, just try again.\n\n# Comparing a random beef track sentiment development to a past track from the same artist\n\nrandom_beef_track = random.choice(beef_tracks)\nchosen_artist = random_beef_track['artist_name']\nalbum_selection = drake_albums if chosen_artist == \"Drake\" else kendrick_albums\n\nrandom_album = random.choice(album_selection)\nrandom_album_tracks = get_album_tracks(random_album['id'], True)\nrandom_track = random.choice(random_album_tracks)\n\nsentiment_development_scores1 = get_track_sentiment_development(random_beef_track['lyrics'], random_beef_track[\"duration_ms\"], False)\nfig, ax = plt.subplots()\nbars = ax.bar(range(len(sentiment_development_scores1)), sentiment_development_scores1)\n\nax.set_xlabel(f\"Index per 4 bars of track\")\nax.set_ylabel('Summed sentiment score')\nax.set_title(f\"Sentiment development of {random_beef_track['name']} by {random_beef_track['artist_name']}\")\n\nplt.show()\n\n###\n\nsentiment_development_scores2 = get_track_sentiment_development(random_track['lyrics'], random_track[\"duration_ms\"], False)\nfig, ax = plt.subplots()\nbars = ax.bar(range(len(sentiment_development_scores2)), sentiment_development_scores2)\n\nax.set_xlabel(f\"Index per 4 bars of track\")\nax.set_ylabel('Summed sentiment score')\nax.set_title(f\"Sentiment development of {random_track['name']} by {random_track['artist_name']}\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThrough my data exploration, I was surprised multiple times looking at the results.\nAnalyze the backgrounds of the two artists, we found that Drake has maintained a high popularity in the mainstream for a long time, while Kendrick’s has maintained less consistency, but reached higher heights. We found that both artists started around the same time, within the same year around 2010.\nAnalyzing the music of the beef, we found multiple interesting extrapolations. Firstly, Kendrick released more music during the feud, especially towards the end in a sequence, without seeing retaliation from Drake. Looking at the popularity of these tracks, it appears all the music involved was highly listened to quite consistently–but the last song of the period, Kendrick’s “Not Like Us”, is by far the most popular track. This is telling for the results of the conflict.\nFinally, from our linguistic analysis, I was quite surprised. We found that Drake’s track, on average, carried more negative sentiment. “Not Like Us”, while still negative, had the least negative average sentiment of any song, which has serious consequences for our sentiment analysis. Looking at the sentiment development over for each beef track, we saw the sentiment change each ~4 bars in each track. While it’s hard to find patterns among them, we can clearly see “Not Like Us” having a very positive ending, which might’ve also influenced the end of the conflict. The rest of the songs during the beef ended quite negatively regardless of earlier sentiment. Through testing the random sentiment comparison generator, I often found that the beef tracks have less variance in sentiment over time compared to the artists’ typical music; but this is not very controlled or measured.\n\n\n\nTying back to the outset of this research, we can first look if we answered the original research question, and then ask what was gained by this. Can we use data to understand some factors that led to Kendrick ‘winning’ his beef with Drake?\nI personally feel this data exploration is only interesting in the context of Kendrick ‘winning’ the conflict. Then, you can start to look at the history and subject matter of the beef and see how what we explored might’ve contributed to that result. It seems the data provided some prety interesting insights into what happened during the beef, and how the fine details of the music might’ve had some correlation with the result. However, I think in general, serious implications can’t really be taken from this data and have conclusions drawn from it, as it’s not substantive enough to seriously say anything.\nSo, to answer the research question, data can definitely help understand the results of the beef. We were absolutely able to glean some interesting information from it. But in order to have any serious conclusions, the data must be heavily built upon. The sentiment score for individual words in these rap songs was often very neutral, most likely because it didn’t recognize a lot of coloquial words, as well as a lot of Proper nouns. The popularity score is also lacking context of the past musics’ popularity “at the time” and seems to mainly capture the popularity of the music now, which might muddy our view of the background of the conflict.\nSo, my verdict is that in order to do some mroe interesting analysis on this beef, one would need more data, and data that is more intricate and generally less available for free. Some ideas I had for data that weren’t immediately available, or were out of scope were: * Data for listens count per song, and follower count per artist * Specific dictionaries for rap language to do more intricate linguistic analysis * Social media data that might’ve followed the trend from an outside perspective\n\n\n\nI’d argue the results aren’t terribly useful to anyone in particular, beyond a fun exercise in analyzing popular trends. At the same time, I wouldn’t argue they’re useless, and might be useful to explore for people into this music, and who might want to further analyze these two artists, and what might contribute to results of beef on the world stage.\n\nprint(\"Thanks for reading! :)\")\n\nThanks for reading! :)"
  },
  {
    "objectID": "posts/Final Project.html#introduction",
    "href": "posts/Final Project.html#introduction",
    "title": "Final Project",
    "section": "",
    "text": "In spring of this year, the pop culture scene erupted as drama unfolded between two of the biggest hip-hop artists of all time, Kendrick Lamar and Drake. During this time, there were countless posts, reactions, and most importantly a groundbreaking series of diss tracks back and forth between the two artists. Now that the dust has settled, the popular consensus is that Kendrick “won” this feud, boosting his reputation and costing Drake a huge blow to his. The stories, allegations, and contexts of this conflict have been endlessly covered online, so I thought it would be a great opportunity to brush over that and approach it from a different angle. That leads me to my research question:\nCan we use data to understand some factors that led to Kendrick ‘winning’ his beef with Drake?\nI intend to answer this question with an exploratory project, hoping to glean interesting insights on the drama using data. We’ll explore the conflict through popular trends, linguistic analysis, and music data.\n\n\n\nWhen exploring data and thinking of ideas for this project, I changed tracks multiple times, exploring pathways with datasets for world cities, veganism, and jazz music. Eventually I circled around to wanting to work with music data and the spotify API, and settled on this topic due to its relevence, recency, and countless angles to approach it from. While I’m not the biggest pop culture or hip-hop fan, I’m very familiar with both artists, their reputations, and what happened in this series of events. I think it provides the perfect opportunity to explore using my interests of music and linguistics.\n\n\n\nAs mentioned, I’m definitely no expert in hip-hop or pop culture, and only hope to glean interesting information on the events that unfolded. I won’t cover any allegations (some of which were very serious) or speculation, but only music and music trends. Finally, I should say I’m personally a huge Kendrick fan and not the biggest fan of Drake’s and this has been the case for quite some time. But I don’t think my bias should affect the outcome of this research beyond my saying that Kendrick ‘won’, which apperas to be the consensus.\nAlso note that many see the kickstart to the conflict between Kendrick and Drake was a song in which Kendrick featured titled “Like that” by Metro Boomin. For simplicity’s sake, we’ll exclude that piece and focus only on the music dropped by our two artists.\nFinally, during the beef there were a couple of smaller diss tracks which, for some reason, are not avaiable on Spotify. Namely, Taylor Made Freestyle and 6:16 in LA. Since they’re not available, they won’t be included in the data."
  },
  {
    "objectID": "posts/Final Project.html#methods",
    "href": "posts/Final Project.html#methods",
    "title": "Final Project",
    "section": "",
    "text": "My analysis will be heavily focused on the data that is available via the Spotify Web API, and hopefully will be limited to not surpass their free usage limits. To supplement the Spotify data, I’ll be using the Genius API to get lyrics for the tracks I analyze. Using this data, I hope to analyze listening trends, linguistic qualities of lyrics, and important relationships of whatever can be extrapolated.\nTo access the Spotify API data, I’ll be using the popular Python wrapper for it called Spotipy for ease of access. Through this, I’ll have access to various endpoints for data on albums, tracks, artists, and musical elements. I’ll source entirely from music by the two artists using this, and build on that by getting the lyrics data from Genius.\nI’ll be getting the data with the requests library. To handle it, I’ll use pandas. To visualize the data I’ll use matplotlib, and for linguistic analysis I’ll use BeautifulSoup and nltk.\n\n\n\nPopularity score refers to the popularity of a single track, ranked by Spotify out of 100, based on amount of plays and recency\n\n\n\n\nTo get started, we need to initialize the project by importing required libraries and packages, then setting up variables to use them.\n\n\nHere, I’ll leave all the major function declarations that will interact with the APIs to get data. There are three sections: * API functions, to interact with the APIs and get data for us to use * Helper functions, to serve as glue between other functions and to help clean our data * Analysis functions, to do stuff with the data and extrapolate information from it\n\n# Genius API functions\n############################################\n\ndef get_track_lyrics(track_name, artist_name):\n    song = genius.search_song(track_name, artist_name)\n    if song:\n        return song.lyrics\n    else:\n        print(f\"Lyrics not found for {track_name} by {artist_name}.\")\n\n# Spotipy API functions\n#############################################\n\ndef get_artist_albums(name):\n    results = sp.search(q=f'artist:{name}', type='artist')\n    artist = results['artists']['items'][0]\n    artist_id = artist['id']\n\n    albums = sp.artist_albums(artist_id, album_type='album')['items']\n    singles = sp.artist_albums(artist_id, album_type='single')['items']\n\n    all_albums = []\n    for album in albums + singles:\n        album_info = {\n            'name': album['name'],\n            'id': album['id'],\n            'artist_name': name,\n            'release_date': album['release_date'],\n            'total_tracks': album['total_tracks'],\n            'album_type': album['album_type']\n        }\n        all_albums.append(album_info)\n\n    return all_albums\n\ndef get_album_tracks(album_id, include_lyrics):\n    tracks = sp.album_tracks(album_id)['items']\n    track_list = []\n    for track in tracks:\n        track_item = sp.track(track[\"id\"])\n        if include_lyrics:\n            track_lyrics = get_track_lyrics(track['name'], track['artists'][0][\"name\"])\n        \n        track_info = {\n            'name': track['name'],\n            'artist_name': track['artists'][0]['name'],\n            'track_number': track['track_number'],\n            'duration_ms': track['duration_ms'],\n            'popularity': track_item['popularity'],\n            'lyrics': track_lyrics if include_lyrics else None\n        }\n        track_list.append(track_info)\n    return track_list\n\n\n## Analysis Functions\n\n# Get the average sentiment score of the words in a song\ndef clean_and_tokenize_lyrics(lyrics):\n    start_index = lyrics.find('Lyrics')\n    if start_index != -1:\n        lyrics = lyrics[start_index + len(\"Lyrics\"):]\n        \n    cleaned_lyrics = re.sub(r'[^\\w\\s]', '', lyrics)\n    cleaned_lyrics = re.sub(r'\\s+', ' ', cleaned_lyrics).strip()\n\n    lyric_words = nltk.word_tokenize(cleaned_lyrics)\n    return lyric_words\n\ndef get_words_avg_sentiment(lyrics, exclude_neutral):\n    words = clean_and_tokenize_lyrics(lyrics)\n    compound_sum = 0\n    word_count = len(words)\n    for word in words:\n        score = sentiment_analyzer.polarity_scores(word)['compound']\n        # optionally exclude neutrals for a more powerful score\n        if exclude_neutral and score == 0:\n            # reduce average divisor to effectively remove 0 scores\n            word_count -= 1\n        compound_sum += score\n    return compound_sum / word_count\n\ndef get_track_sentiment_development(lyrics, duration_ms, exclude_neutral):\n    # assuming an average of 100bpm, we get ~2.4 seconds per bar. Our period will be ~8 bars\n    words = clean_and_tokenize_lyrics(lyrics)\n    total_bars = duration_ms / 1000 / 2.4\n    words_per_bar = len(words) / total_bars\n    words_per_4_bars = round(words_per_bar * 4)\n\n    grouped_sentiment_scores = []\n    index = 0\n    counter = 0\n    cur_score = 0\n    while index &lt; len(words):\n        if counter == words_per_4_bars:\n            grouped_sentiment_scores.append(cur_score)\n            counter = 0\n            cur_score = 0\n        cur_score += sentiment_analyzer.polarity_scores(words[index])[\"compound\"]\n        index += 1\n        counter += 1\n    return grouped_sentiment_scores"
  },
  {
    "objectID": "posts/Final Project.html#results",
    "href": "posts/Final Project.html#results",
    "title": "Final Project",
    "section": "",
    "text": "Now that we have a strategy and infrastructure in place to get the data, we can get it into our environment and start organizing it for analysis.\n\n\nThis cell will contain a lot of API calls while defining the most important variables. Have caution calling it more than once, as rate limits might start applying.\n\n# Get all albums from both artists respectively\n    # API call get_artists_albums\nkendrick_albums = get_artist_albums(\"Kendrick Lamar\")\ndrake_albums = get_artist_albums(\"Drake\")\n\n\n# Inject popularity score to each album via API call\nfor album in kendrick_albums:\n    tracks = get_album_tracks(album['id'], False)\n    album['avg_popularity'] = calc_album_popularity(tracks)\nfor album in drake_albums:\n    tracks = get_album_tracks(album['id'], False)\n    album['avg_popularity'] = calc_album_popularity(tracks)\n\n\n# Clean corrupted item\ndrake_albums = [album for album in drake_albums if len(album['release_date']) == 10]\nkendrick_albums = [album for album in kendrick_albums if len(album['release_date']) == 10]\n\n# Optionally combine all their albums and sort them by release date\nkendrick_and_drake_albums = kendrick_albums + drake_albums\nkendrick_and_drake_albums.sort(key=lambda x: x['release_date'])\n\n# Define the start point of the beef\nsplit_index = find_item_index(kendrick_and_drake_albums, \"Push Ups\")\n\n# Create split of albums from before and during the beef\nbeef_singles = kendrick_and_drake_albums[split_index:]\npre_beef_albums = kendrick_and_drake_albums[:split_index]\n\n# Exclude post-beef track from list\nbeef_singles = [album for album in beef_singles if album[\"name\"] != \"Sideways\"]\n\n# Swap Meet the Grahams (later) and Family Matters (earlier), which were released on the same day\nmtg_index = find_item_index(beef_singles, \"Meet the Grahams\")\nfm_index = find_item_index(beef_singles, \"Family Matters\")\nif mtg_index != -1 and fm_index != -1:\n    beef_singles[fm_index], beef_singles[mtg_index] = beef_singles[mtg_index], beef_singles[fm_index]\n\n\nbeef_tracks = []\nfor single in beef_singles:\n    track = get_album_tracks(single[\"id\"], True)\n    beef_tracks.append(track[0])\n\n\n\n\n\n# Drake all albums and release years, showing popularity\ndrake_release_dates = [datetime.strptime(album['release_date'], '%Y-%m-%d') for album in drake_albums]\ndrake_popularities = [album[\"avg_popularity\"] for album in drake_albums]\ndrake_album_colors = ['green' if album['album_type'].lower() == 'album' else 'goldenrod' for album in drake_albums]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(drake_release_dates, drake_popularities, color=drake_album_colors,width=30)\n\nplt.title('Popularity scores of all Drake releases', fontsize=16)\nplt.xlabel('Album Release Date', fontsize=12)\nplt.ylabel('Popularity score', fontsize=12)\n\nplt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n\nlegend_elements = [Patch(facecolor='goldenrod', edgecolor='goldenrod', label='Single'),\n                   Patch(facecolor='green', edgecolor='green', label='Album')]\nplt.legend(handles=legend_elements)\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Kendrick all albums and release years, showing popularity\nkendrick_release_dates = [datetime.strptime(album['release_date'], '%Y-%m-%d') for album in kendrick_albums]\nkendrick_popularities = [album[\"avg_popularity\"] for album in kendrick_albums]\nkendrick_album_colors = ['green' if album['album_type'].lower() == 'album' else 'goldenrod' for album in kendrick_albums]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(kendrick_release_dates, kendrick_popularities, color=kendrick_album_colors,width=30)\n\nplt.title('Popularity scores of all Kendrick releases', fontsize=16)\nplt.xlabel('Album Release Date', fontsize=12)\nplt.ylabel('Popularity score', fontsize=12)\n\nplt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n\nlegend_elements = [Patch(facecolor='goldenrod', edgecolor='goldenrod', label='Single'),\n                   Patch(facecolor='green', edgecolor='green', label='Album')]\nplt.legend(handles=legend_elements)\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(12, 6))\n\nplt.plot(drake_release_dates, drake_popularities, 'o', label='Drake', color=\"crimson\")\n\nplt.plot(kendrick_release_dates, kendrick_popularities, 'o', label='Kendrick Lamar', color=\"skyblue\")\n\nplt.title(\"Both Artists' Releases Popularities Over Time\", fontsize=16)\nplt.xlabel(\"Release Date\", fontsize=12)\nplt.ylabel(\"Popularity Score\", fontsize=12)\nplt.legend()\n\nplt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n\nplt.grid(True, linestyle='--', alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nbeef_titles = [f\"{album['name']} \\n {album['artist_name']}\" for album in beef_singles]\nbeef_release_dates = [datetime.strptime(album['release_date'], '%Y-%m-%d') for album in beef_singles]\nbeef_colors = [\"crimson\" if \"Drake\" in track[\"artist_name\"] else \"skyblue\" for track in beef_tracks]\nbeef_popularities = [track['popularity'] for track in beef_tracks]\n\nfig, ax = plt.subplots(figsize=(12, 6))\ny_levels = [1.5, 1.5, 1.5, 2, 1.5]\n\nfor i, (date, title, color) in enumerate(zip(beef_release_dates, beef_titles, beef_colors)):\n    y = y_levels[i % len(y_levels)]\n    ax.scatter(date, y, s=75, color=color)\n    ax.annotate(title, (date, y), xytext=(10, 0), \n                textcoords='offset points', ha='center', va='top',\n                rotation=45)\n\nax.set_ylim(1, 2.5)\nax.set_yticks([])  \n\nplt.title('Beef Release Timeline', fontsize=16)\nplt.xlabel('Release Date', fontsize=12)\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Popularity of each beef track\nbeef_popularities = [track['popularity'] for track in beef_tracks]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(beef_titles, beef_popularities, color=beef_colors)\n\nplt.title('Popularity of each track during the beef', fontsize=16)\nplt.xlabel('Track Title', fontsize=12)\nplt.ylabel('Popularity score', fontsize=12)\n\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height,\n             f'{height}',\n             ha='center', va='bottom')\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n# Average sentiment track by track of beef\nbeef_avg_sentiments = [get_words_avg_sentiment(track['lyrics'], False) for track in beef_tracks]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(beef_titles, beef_avg_sentiments, color=beef_colors)\n\nplt.title('Average sentiment score of beef track lyrics, including neutral words', fontsize=16)\nplt.xlabel('Track Title', fontsize=12)\nplt.ylabel('Words average sentiment score', fontsize=12)\n\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height,\n             f'{height}',\n             ha='center', va='bottom')\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Average sentiment track by track of beef\nbeef_avg_sentiments = [get_words_avg_sentiment(track['lyrics'], True) for track in beef_tracks]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(beef_titles, beef_avg_sentiments, color=beef_colors)\n\nplt.title('Average sentiment score of beef track lyrics, excluding neutral words', fontsize=16)\nplt.xlabel('Track Title', fontsize=12)\nplt.ylabel('Words average sentiment score', fontsize=12)\n\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height,\n             f'{height}',\n             ha='center', va='bottom')\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Sentiment development during each track\n\nfor track in beef_tracks:\n    sentiment_development_scores = get_track_sentiment_development(track['lyrics'], track[\"duration_ms\"], False)\n    fig, ax = plt.subplots()\n    bars = ax.bar(range(len(sentiment_development_scores)), sentiment_development_scores)\n    \n    ax.set_xlabel(f\"Index per 4 bars of track\")\n    ax.set_ylabel('Summed sentiment score')\n    ax.set_title(f\"Sentiment development of {track['name']} by {track['artist_name']}\")\n    \n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that this functionality occasionally won’t work due to inconsistency with the API. If it times out, just try again.\n\n# Comparing a random beef track sentiment development to a past track from the same artist\n\nrandom_beef_track = random.choice(beef_tracks)\nchosen_artist = random_beef_track['artist_name']\nalbum_selection = drake_albums if chosen_artist == \"Drake\" else kendrick_albums\n\nrandom_album = random.choice(album_selection)\nrandom_album_tracks = get_album_tracks(random_album['id'], True)\nrandom_track = random.choice(random_album_tracks)\n\nsentiment_development_scores1 = get_track_sentiment_development(random_beef_track['lyrics'], random_beef_track[\"duration_ms\"], False)\nfig, ax = plt.subplots()\nbars = ax.bar(range(len(sentiment_development_scores1)), sentiment_development_scores1)\n\nax.set_xlabel(f\"Index per 4 bars of track\")\nax.set_ylabel('Summed sentiment score')\nax.set_title(f\"Sentiment development of {random_beef_track['name']} by {random_beef_track['artist_name']}\")\n\nplt.show()\n\n###\n\nsentiment_development_scores2 = get_track_sentiment_development(random_track['lyrics'], random_track[\"duration_ms\"], False)\nfig, ax = plt.subplots()\nbars = ax.bar(range(len(sentiment_development_scores2)), sentiment_development_scores2)\n\nax.set_xlabel(f\"Index per 4 bars of track\")\nax.set_ylabel('Summed sentiment score')\nax.set_title(f\"Sentiment development of {random_track['name']} by {random_track['artist_name']}\")\n\nplt.show()"
  },
  {
    "objectID": "posts/Final Project.html#discussion",
    "href": "posts/Final Project.html#discussion",
    "title": "Final Project",
    "section": "",
    "text": "Through my data exploration, I was surprised multiple times looking at the results.\nAnalyze the backgrounds of the two artists, we found that Drake has maintained a high popularity in the mainstream for a long time, while Kendrick’s has maintained less consistency, but reached higher heights. We found that both artists started around the same time, within the same year around 2010.\nAnalyzing the music of the beef, we found multiple interesting extrapolations. Firstly, Kendrick released more music during the feud, especially towards the end in a sequence, without seeing retaliation from Drake. Looking at the popularity of these tracks, it appears all the music involved was highly listened to quite consistently–but the last song of the period, Kendrick’s “Not Like Us”, is by far the most popular track. This is telling for the results of the conflict.\nFinally, from our linguistic analysis, I was quite surprised. We found that Drake’s track, on average, carried more negative sentiment. “Not Like Us”, while still negative, had the least negative average sentiment of any song, which has serious consequences for our sentiment analysis. Looking at the sentiment development over for each beef track, we saw the sentiment change each ~4 bars in each track. While it’s hard to find patterns among them, we can clearly see “Not Like Us” having a very positive ending, which might’ve also influenced the end of the conflict. The rest of the songs during the beef ended quite negatively regardless of earlier sentiment. Through testing the random sentiment comparison generator, I often found that the beef tracks have less variance in sentiment over time compared to the artists’ typical music; but this is not very controlled or measured.\n\n\n\nTying back to the outset of this research, we can first look if we answered the original research question, and then ask what was gained by this. Can we use data to understand some factors that led to Kendrick ‘winning’ his beef with Drake?\nI personally feel this data exploration is only interesting in the context of Kendrick ‘winning’ the conflict. Then, you can start to look at the history and subject matter of the beef and see how what we explored might’ve contributed to that result. It seems the data provided some prety interesting insights into what happened during the beef, and how the fine details of the music might’ve had some correlation with the result. However, I think in general, serious implications can’t really be taken from this data and have conclusions drawn from it, as it’s not substantive enough to seriously say anything.\nSo, to answer the research question, data can definitely help understand the results of the beef. We were absolutely able to glean some interesting information from it. But in order to have any serious conclusions, the data must be heavily built upon. The sentiment score for individual words in these rap songs was often very neutral, most likely because it didn’t recognize a lot of coloquial words, as well as a lot of Proper nouns. The popularity score is also lacking context of the past musics’ popularity “at the time” and seems to mainly capture the popularity of the music now, which might muddy our view of the background of the conflict.\nSo, my verdict is that in order to do some mroe interesting analysis on this beef, one would need more data, and data that is more intricate and generally less available for free. Some ideas I had for data that weren’t immediately available, or were out of scope were: * Data for listens count per song, and follower count per artist * Specific dictionaries for rap language to do more intricate linguistic analysis * Social media data that might’ve followed the trend from an outside perspective\n\n\n\nI’d argue the results aren’t terribly useful to anyone in particular, beyond a fun exercise in analyzing popular trends. At the same time, I wouldn’t argue they’re useless, and might be useful to explore for people into this music, and who might want to further analyze these two artists, and what might contribute to results of beef on the world stage.\n\nprint(\"Thanks for reading! :)\")\n\nThanks for reading! :)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Final Project",
    "section": "",
    "text": "Final Project\n\n\n\n\n\n\n\n\n\n\n\nAug 4, 2024\n\n\nJohn Flanagan\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nAug 4, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nAug 1, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  }
]